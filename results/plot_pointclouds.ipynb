{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# plotting function\n",
    "def plot_3d_point_cloud(\n",
    "    pc,\n",
    "    show=True,\n",
    "    show_axis=True,\n",
    "    in_u_sphere=True,\n",
    "    marker=\".\",\n",
    "    c=\"b\",\n",
    "    s=4,\n",
    "    alpha=0.8,\n",
    "    figsize=(5, 5),\n",
    "    elev=10,\n",
    "    azim=10,\n",
    "    miv=None,\n",
    "    mav=None,\n",
    "    squeeze=0.8,\n",
    "    axis=None,\n",
    "    title=None,\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    x, y, z = (pc.squeeze(0)[:, 2], pc.squeeze(0)[:, 0], pc.squeeze(0)[:, 1])\n",
    "\n",
    "    if axis is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    else:\n",
    "        ax = axis\n",
    "        fig = axis\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    sc = ax.scatter(x, y, z, marker=marker, c=c, s=s, alpha=alpha, *args, **kwargs)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    if in_u_sphere:\n",
    "        ax.set_xlim3d(-0.5, 0.5)\n",
    "        ax.set_ylim3d(-0.5, 0.5)\n",
    "        ax.set_zlim3d(-0.5, 0.5)\n",
    "        miv = -0.5\n",
    "        mav = 0.5\n",
    "        plt.tight_layout()\n",
    "\n",
    "    else:\n",
    "        if miv is None:\n",
    "            miv = squeeze * np.min(\n",
    "                [np.min(x), np.min(y), np.min(z)]\n",
    "            )  # Multiply with 'squeeze' to squeeze free-space.\n",
    "        if mav is None:\n",
    "            mav = squeeze * np.max([np.max(x), np.max(y), np.max(z)])\n",
    "        ax.set_xlim(miv, mav)\n",
    "        ax.set_ylim(miv, mav)\n",
    "        ax.set_zlim(miv, mav)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if not show_axis:\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    if \"c\" in kwargs:\n",
    "        plt.colorbar(sc)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return fig, miv, mav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models import pointnet_cls, pointnet_utils\n",
    "from src import FPSSampler, SampleNet\n",
    "from src.pctransforms import OnUnitCube, PointcloudRandomInputDropout, PointcloudToTensor\n",
    "from src.chamfer_distance import ChamferDistance\n",
    "from data.facescape_loader import FaceScape\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "# dataset\n",
    "transforms = torchvision.transforms.Compose([PointcloudToTensor(), OnUnitCube()])\n",
    "testset = FaceScape(\n",
    "    1024,\n",
    "    transforms=transforms,\n",
    "    train=False,\n",
    "    annotations=\"all_annotations1024.npy\",\n",
    "    contrastive=False\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "# add noise function\n",
    "def add_noise(data, model,\n",
    "              learn_noise=False,\n",
    "              resample=False,\n",
    "              pointwise=False,\n",
    "              sigma=0.):\n",
    "    \n",
    "    if learn_noise:\n",
    "        if resample:\n",
    "            scale = model.noise_std[0].abs()\n",
    "            loc = model.noise_mean[0]\n",
    "            \n",
    "        elif pointwise:\n",
    "            scale, loc = model.get_std(data[0])\n",
    "        else:\n",
    "            new_data = data[0] + model.noise[0]\n",
    "        \n",
    "        if resample or pointwise:\n",
    "            noise = tod.Normal(loc=loc, scale=scale.abs() + 1e-10)\n",
    "            resampled = noise.rsample()\n",
    "            new_data = data[0] + resampled\n",
    "\n",
    "            return new_data, data[1]\n",
    "    else:\n",
    "        new_data = data[0] + torch.normal(\n",
    "                mean=0.0, std=sigma, size=data[0].shape\n",
    "            ).to(data.device)\n",
    "    \n",
    "    return new_data, data[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random sample\n",
    "inputs, target, _ = next(iter(testloader))\n",
    "\n",
    "# plot input\n",
    "_= plot_3d_point_cloud(inputs, title=\"Complete input point cloud\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Exp Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet_exp = pointnet_cls.get_model(20, use_enc_stn=True, num_in_points=1024).eval().to(device)\n",
    "\n",
    "pointnet_gender = pointnet_cls.get_model(2, use_enc_stn=True, num_in_points=1024).eval().to(device)\n",
    "\n",
    "sampler_s = SampleNet(\n",
    "    num_out_points=64,\n",
    "    bottleneck_size=128,\n",
    "    group_size=7,\n",
    "    initial_temperature=1.0,\n",
    "    input_shape=\"bnc\",\n",
    "    output_shape=\"bnc\",\n",
    "    use_stn=True,\n",
    "    device=\"cpu\",\n",
    "    learn_noise=False,\n",
    "    pointwise_dist=False,\n",
    ").eval().to(device)\n",
    "\n",
    "sampler_f = FPSSampler(\n",
    "                num_out_points=64,\n",
    "                permute=True,\n",
    "                input_shape=\"bnc\",\n",
    "                output_shape=\"bnc\",\n",
    "                learn_noise=False,\n",
    "                pointwise_dist=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sampled point cloud exp: 64 points\n",
    "EXP_SAMPLENET64 = \"../facescape/log/exp/SAMPLENET64/train_sampler_best.pth\"\n",
    "EXP_POINTNET64 = \"../facescape/log/exp/SAMPLENET64/train_model_best.pth\"\n",
    "EXP_FPS64 = \"../facescape/log/exp/FPS64/train_sampler_best.pth\"\n",
    "EXP_POINTNET64_FPS = \"../facescape/log/exp/FPS64/train_model_best.pth\"\n",
    "\n",
    "\n",
    "def run_exp_samplenet(inputs, target, sampler, model_path, sampler_path):\n",
    "    pointnet_exp.load_state_dict(torch.load(model_path))\n",
    "    sampler.load_state_dict(torch.load(sampler_path))\n",
    "\n",
    "    # sample using samplenet\n",
    "    if \"FPS\" not in sampler_path:\n",
    "        p0_simplified, p0_projected, original = sampler(inputs.to(device))\n",
    "        sampled_data = (p0_projected, target)\n",
    "    else:\n",
    "        sampled_data = sampler(inputs.to(device))\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "sampled_data = run_exp_samplenet(inputs, target, sampler_s, EXP_POINTNET64, EXP_SAMPLENET64)\n",
    "p0_projected, target = sampled_data\n",
    "# plot sampled data\n",
    "_ = plot_3d_point_cloud(p0_projected.to(\"cpu\"), title=\"Sampled point cloud (exp)\")\n",
    "\n",
    "# inference\n",
    "x, trans_feat = pointnet_exp(p0_projected)\n",
    "_, pred = torch.max(x.data, 1)\n",
    "t = target[:, -1]\n",
    "# loss = pointnet_exp.get_loss()(x, target, trans_feat)\n",
    "correct = (pred.to(\"cpu\") == t.to(\"cpu\")).sum()\n",
    "total = t.size(0)\n",
    "correct = float(correct.item()) / total\n",
    "\n",
    "print(correct, pred, t)\n",
    "# print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_FPS64 = \"../facescape/log/gender/FPS64/train_sampler_best.pth\"\n",
    "GENDER_SAMPLENET64 = \"../facescape/log/gender/SAMPLENET64/train_sampler_best.pth\"\n",
    "GENDER_POINTNET64 = \"../facescape/log/gender/SAMPLENET64/train_model_best.pth\"\n",
    "GENDER_POINTNET64_FPS = \"../facescape/log/gender/FPS64/train_model_best.pth\"\n",
    "\n",
    "def run_gender_samplenet(inputs, target, sampler, model_path, sampler_path):\n",
    "    pointnet_gender.load_state_dict(torch.load(model_path))\n",
    "    sampler.load_state_dict(torch.load(sampler_path))\n",
    "\n",
    "    if \"FPS\" not in sampler_path:\n",
    "        p0_simplified, p0_projected, original = sampler(inputs.to(device))\n",
    "        sampled_data = (p0_projected, target)\n",
    "    else:\n",
    "        sampled_data = sampler(inputs.to(device))\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "sampled_data = run_gender_samplenet(inputs, target, sampler_s, GENDER_POINTNET64, GENDER_SAMPLENET64)\n",
    "p0_projected, target = sampled_data\n",
    "# plot sampled data\n",
    "_ = plot_3d_point_cloud(p0_projected.to(\"cpu\"), title=\"Sampled point cloud (gender)\")\n",
    "\n",
    "# inference\n",
    "x, trans_feat = pointnet_gender(p0_projected)\n",
    "_, pred = torch.max(x.data, 1)\n",
    "t = target[:, -2]\n",
    "# loss = pointnet.get_loss()(x, target, trans_feat)\n",
    "correct = (pred.to(\"cpu\") == t.to(\"cpu\")).sum()\n",
    "total = t.size(0)\n",
    "correct = float(correct.item()) / total\n",
    "\n",
    "print(correct, pred, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot private point cloud exp-gender: 64 points\n",
    "import torch.distributions as tod\n",
    "\n",
    "# CSN + Pointwise\n",
    "CSN_POINTWISE_SAMPLER = \"../facescape/log/csn_pointwise_discrim/5/50/exp_gender_1/SAMPLENET64/train_sampler_best.pth\"\n",
    "CSN_POINTWISE_POINTNET = \"../facescape/log/csn_pointwise_discrim/5/50/exp_gender_1/SAMPLENET64/train_model_best.pth\"\n",
    "CSN_POINTWISE_ATTACKER = \"../facescape/log/csn_pointwise_discrim/5/50/exp_gender_1/finetune/train_model_best.pth\"\n",
    "\n",
    "sampler = SampleNet(\n",
    "    num_out_points=64,\n",
    "    bottleneck_size=128,\n",
    "    group_size=7,\n",
    "    initial_temperature=1.0,\n",
    "    input_shape=\"bnc\",\n",
    "    output_shape=\"bnc\",\n",
    "    use_stn=True,\n",
    "    device=\"cpu\",\n",
    "    learn_noise=True,\n",
    "    pointwise_dist=True,\n",
    ").eval().to(device)\n",
    "\n",
    "attacker = pointnet_cls.get_model(2, use_enc_stn=True, num_in_points=1024).eval().to(device)\n",
    "\n",
    "pointnet_exp.load_state_dict(torch.load(CSN_POINTWISE_POINTNET))\n",
    "sampler.load_state_dict(torch.load(CSN_POINTWISE_SAMPLER))\n",
    "attacker.load_state_dict(torch.load(CSN_POINTWISE_ATTACKER))\n",
    "\n",
    "# sample using samplenet\n",
    "p0_simplified, p0_projected, original = sampler(inputs.to(device))\n",
    "sampled_data = (p0_projected, target)\n",
    "sampled_data = add_noise(\n",
    "    sampled_data,\n",
    "    sampler,\n",
    "    learn_noise=True,\n",
    "    resample=False,\n",
    "    pointwise=True\n",
    ")\n",
    "\n",
    "# plot sampled data\n",
    "_ = plot_3d_point_cloud(sampled_data[0].detach().to(\"cpu\"), title=\"CSN Pointwise (exp-gender)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
